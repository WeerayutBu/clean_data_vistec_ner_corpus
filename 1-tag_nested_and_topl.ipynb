{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from fn_test import _test_overlapping\n",
    "import glob\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags and save nested entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_nested_ner(path_raw_data, path_save, tag, group, max_levels, engine):\n",
    "    path_save_nested     = path_save+'/nested_ner/'+tag+'/'\n",
    "    path_save_topl       = path_save+'/flatten_ner/'+tag+'/'\n",
    "\n",
    "    ### Find raw datas.\n",
    "    filenames_csv        = [f for f in glob.glob(path_raw_data+'**/*.csv', recursive=True)]\n",
    "    filename_json        = [f for f in glob.glob(path_raw_data+'**/*.json', recursive=True)]\n",
    "\n",
    "    # Show all files to download\n",
    "#     print('\\n-- Input paths --')\n",
    "#     print('CSV files')\n",
    "#     [print(f) for f in filenames_csv]\n",
    "\n",
    "#     print('\\nJson files')\n",
    "#     [print(f) for f in filename_json]\n",
    "\n",
    "#     print('\\n-- Output paths --')\n",
    "#     print('Output path: nested_ner  : ', path_save_topl)\n",
    "#     print('Output path: flatten_ner : ', path_save_topl)\n",
    "\n",
    "    ### Tags nested ner ###\n",
    "    temp_sentences   = []\n",
    "    temp_overlappint = {}\n",
    "    for filen_csv, filen_json in zip(filenames_csv, filename_json):\n",
    "        overlap_en       = []\n",
    "        # Check the file name to load and save.\n",
    "        checklotdir_csv   = filen_csv.split('/')[-2]\n",
    "        checklotdir_json  = filen_json.split('/')[-2]\n",
    "        save_file_name    = filen_json.split('/')[-2]\n",
    "\n",
    "        assert checklotdir_csv == checklotdir_json\n",
    "        print('\\n',checklotdir_csv, checklotdir_json)\n",
    "        print('{}'.format(filen_csv.split('/')[-1]))\n",
    "        print('{}'.format( filen_json.split('/')[-1]))\n",
    "\n",
    "        ## Create output files\n",
    "        sftags_nested_ner = open(path_save_nested+save_file_name+'_nested.data', 'w')\n",
    "\n",
    "        ## Load CSV file\n",
    "        data_csv  = pd.read_csv(filen_csv)\n",
    "\n",
    "        ## Load Json file \n",
    "        read_file = open(filen_json, \"r\")\n",
    "        data_json = json.load(read_file)\n",
    "\n",
    "        ## Tags entities\n",
    "        for idx, datas in enumerate(zip(data_json, data_csv['ssg'], data_csv['text_clean'])):\n",
    "\n",
    "            ## Remove pipe\n",
    "            datas = remove_pipe(datas[0],datas[1],datas[2])\n",
    "\n",
    "            ## Prepare data\n",
    "            entities            = datas['entities']\n",
    "            text                = datas['text']\n",
    "            token_idx_en        = get_all_entities_index(entities)\n",
    "            words_token         = token_en2words(token_idx_en, text, engine=engine)\n",
    "            words_tags_nested_  = tags_nested(words_token, entities, max_levels, group=group)\n",
    "            words_tags_nested   = tags_bioes(words_tags_nested_, max_levels)\n",
    "            \n",
    "            ## Test\n",
    "            #Check overlappint entities:\n",
    "            if(_test_overlapping(words_tags_nested_)):\n",
    "                #print('Overlapping:',idx)\n",
    "                overlap_en.append(idx)\n",
    "                continue\n",
    "                \n",
    "            if(_check_tokenizer(text, words_token)):\n",
    "                print('Tokenizer error',idx)\n",
    "                raise idx\n",
    "            \n",
    "            if(False):\n",
    "                _show_details(datas, words_tags_nested_)\n",
    "                return 0\n",
    "            \n",
    "            ## Save nested corpus ##\n",
    "            save_data(words_tags_nested, sftags_nested_ner, nested=True)\n",
    "            temp_sentences.append(words_tags_nested)\n",
    "        sftags_nested_ner.close()\n",
    "        \n",
    "        # Report error\n",
    "        temp_overlappint[str(save_file_name)] = [str(x) for x in overlap_en]\n",
    "        \n",
    "    ### Save flatten ner(Top-level) ###\n",
    "    srcf = open(path_save_topl+'data.src', 'w')\n",
    "    trgf = open(path_save_topl+'data.trg', 'w')\n",
    "\n",
    "    for sent in temp_sentences:\n",
    "        source = [token[0] for token in sent]\n",
    "        target = [token[1] for token in sent]\n",
    "        srcf.writelines('|'.join(source)+'\\n')\n",
    "        trgf.writelines('|'.join(target)+'\\n')\n",
    "    srcf.close()\n",
    "    trgf.close()\n",
    "    \n",
    "    print('\\nOverlapping sents no. :',temp_overlappint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_tokenizer(text, words_token):\n",
    "    all_chars_len  = len(text)\n",
    "    all_tokens_len = np.sum([len(x) for x in words_token])\n",
    "#     print(all_chars_len)\n",
    "#     print(all_tokens_len, words_token)\n",
    "    assert all_chars_len == all_tokens_len\n",
    "\n",
    "def _show_details(datas, words_tags_nested_):\n",
    "    check_sentence(datas)\n",
    "    [print(s) for s in words_tags_nested_]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " datalot1 datalot1\n",
      "ner_lot1_050620_num_word_192449_num_tag_21688.csv\n",
      "ner_lot1_050620_num_word_192449_num_tag_21688.json\n",
      "\n",
      " datalot2 datalot2\n",
      "ner_lot2_050620_num_word_195530_num_tag_32232.csv\n",
      "ner_lot2_050620_num_word_195530_num_tag_32232.json\n",
      "\n",
      " datalot3 datalot3\n",
      "ner_lot3_050620_num_word_198387_num_tag_34144.csv\n",
      "ner_lot3_050620_num_word_198387_num_tag_34144.json\n",
      "\n",
      " datalot4 datalot4\n",
      "ner_lot4_050620_num_word_401684_num_tag_70076.csv\n",
      "ner_lot4_050620_num_word_401684_num_tag_70076.json\n",
      "\n",
      "Overlapping sents no. : {'datalot1': ['151', '185', '261', '307', '317', '321', '324', '461', '514', '518', '519', '520', '522', '524', '525', '526', '527', '528', '532', '533', '535', '554', '556', '558', '559', '561', '563', '564', '573', '574', '575', '577', '581', '624', '625', '643', '656', '672', '683', '687', '690', '695', '701', '711', '714', '723', '726', '791'], 'datalot2': ['12', '17', '39', '51', '55', '74', '76', '77', '78', '81', '92', '124', '126', '134', '138', '151', '152', '153', '157', '191', '198', '215', '219', '237', '282', '308', '318', '350', '388', '391', '393', '394', '400', '403', '407', '410', '411', '415', '416', '420', '425', '428', '464', '475', '506', '593'], 'datalot3': ['23', '25', '49', '65', '67', '110', '116', '118', '120', '125', '138', '166', '183', '184', '207', '248', '249', '250', '255', '263', '274', '275', '278', '279', '280', '284', '286', '323', '325', '336', '339', '348', '388', '389', '391', '417', '418', '419', '421', '423', '424', '425', '427', '428', '429', '432', '433', '434', '435', '437', '440', '443', '444', '445', '446', '448', '449', '455', '467', '477', '495', '499', '500', '509', '511', '514', '519', '524', '542', '544', '556', '560', '568', '572'], 'datalot4': ['10', '65', '74', '80', '84', '92', '98', '99', '100', '101', '110', '155', '169', '171', '188', '243', '249', '251', '258', '264', '265', '288', '435', '437', '438', '467', '491', '505', '516', '569', '577', '578', '601', '619', '620', '621', '624', '640', '651', '658', '666', '667', '668', '726', '734', '735', '740', '752', '812', '813', '817', '818', '819', '821', '822', '833', '841', '843', '844', '849', '857', '865', '885', '888', '895', '928', '931', '932', '934', '936', '939', '942', '943', '945', '946', '947', '948', '950', '951', '952', '957', '958', '959', '960', '961', '963', '964', '967', '968', '969', '970', '971', '972', '973', '974', '975', '977', '978', '980', '982', '984', '985', '987', '988', '990', '992', '994', '995', '996', '997', '998', '999', '1000', '1001', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1029', '1032', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1057', '1058', '1059', '1152', '1161', '1189', '1193', '1199']}\n",
      "\n",
      " datalot1 datalot1\n",
      "ner_lot1_050620_num_word_192449_num_tag_21688.csv\n",
      "ner_lot1_050620_num_word_192449_num_tag_21688.json\n",
      "\n",
      " datalot2 datalot2\n",
      "ner_lot2_050620_num_word_195530_num_tag_32232.csv\n",
      "ner_lot2_050620_num_word_195530_num_tag_32232.json\n",
      "\n",
      " datalot3 datalot3\n",
      "ner_lot3_050620_num_word_198387_num_tag_34144.csv\n",
      "ner_lot3_050620_num_word_198387_num_tag_34144.json\n",
      "\n",
      " datalot4 datalot4\n",
      "ner_lot4_050620_num_word_401684_num_tag_70076.csv\n",
      "ner_lot4_050620_num_word_401684_num_tag_70076.json\n",
      "\n",
      "Overlapping sents no. : {'datalot1': ['151', '185', '261', '307', '317', '321', '324', '461', '514', '518', '519', '520', '522', '524', '525', '526', '527', '528', '532', '533', '535', '554', '556', '558', '559', '561', '563', '564', '573', '574', '575', '577', '581', '624', '625', '643', '656', '672', '683', '687', '690', '695', '701', '711', '714', '723', '726', '791'], 'datalot2': ['12', '17', '39', '51', '55', '74', '76', '77', '78', '81', '92', '124', '126', '134', '138', '151', '152', '153', '157', '191', '198', '215', '219', '237', '282', '308', '318', '350', '388', '391', '393', '394', '400', '403', '407', '410', '411', '415', '416', '420', '425', '428', '464', '475', '506', '593'], 'datalot3': ['23', '25', '49', '65', '67', '110', '116', '118', '120', '125', '138', '166', '183', '184', '207', '248', '249', '250', '255', '263', '274', '275', '278', '279', '280', '284', '286', '323', '325', '336', '339', '348', '388', '389', '391', '417', '418', '419', '421', '423', '424', '425', '427', '428', '429', '432', '433', '434', '435', '437', '440', '443', '444', '445', '446', '448', '449', '455', '467', '477', '495', '499', '500', '509', '511', '514', '519', '524', '542', '544', '556', '560', '568', '572'], 'datalot4': ['10', '65', '74', '80', '84', '92', '98', '99', '100', '101', '110', '155', '169', '171', '188', '243', '249', '251', '258', '264', '265', '288', '435', '437', '438', '467', '491', '505', '516', '569', '577', '578', '601', '619', '620', '621', '624', '640', '651', '658', '666', '667', '668', '726', '734', '735', '740', '752', '812', '813', '817', '818', '819', '821', '822', '833', '841', '843', '844', '849', '857', '865', '885', '888', '895', '928', '931', '932', '934', '936', '939', '942', '943', '945', '946', '947', '948', '950', '951', '952', '957', '958', '959', '960', '961', '963', '964', '967', '968', '969', '970', '971', '972', '973', '974', '975', '977', '978', '980', '982', '984', '985', '987', '988', '990', '992', '994', '995', '996', '997', '998', '999', '1000', '1001', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1029', '1032', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1057', '1058', '1059', '1152', '1161', '1189', '1193', '1199']}\n",
      "CPU times: user 2min 28s, sys: 535 ms, total: 2min 28s\n",
      "Wall time: 2min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This path for loading raw data from the VISTEC nested ner corpus.\n",
    "path_corpus               = '/home/module/data/vistec_corpus/NER_dataset_20200629/'\n",
    "path_save                 = '/home/module/data/vistec_newmm4L'\n",
    "# path_save                 = './results/test2'\n",
    "\n",
    "max_levels                = 8\n",
    "engine                    = \"newmm\"  # ['newmm', 'longest', 'deepcut', 'icu', 'ulmfit', 'attacut']\n",
    "create_save_dir(path_save)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tags_nested_ner(path_corpus, path_save, 'maintags', True, max_levels, engine)\n",
    "    tags_nested_ner(path_corpus, path_save, 'subtags', False, max_levels, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 sents\n",
    "# attacut : 1min 22s\n",
    "# newmm   : 4.35 s\n",
    "\n",
    "# all\n",
    "# attacut : 28min 44s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_tokenizer(text, words_token):\n",
    "    all_chars_len  = len(text)\n",
    "    all_tokens_len = np.sum([len(x) for x in words_token])\n",
    "#     print([len(x) for x in words_token])\n",
    "#     print(all_chars_len)\n",
    "#     print(all_tokens_len, words_token)\n",
    "    assert all_chars_len == all_tokens_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "text = \"เรา รักภาษาบ้านเกิด234\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['เรา', ' ', 'รัก', 'ภาษา', 'บ้าน', 'เกิด', ' ', '234', ' ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icu_token = word_tokenize(text, engine=\"icu\")\n",
    "icu_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['เรา', ' ', 'รัก', 'ภาษา', 'บ้าน', 'เกิด', '234']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacut_token = word_tokenize(text, engine=\"attacut\")\n",
    "attacut_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['เรา', ' ', 'รัก', 'ภาษา', 'บ้านเกิด', '234']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmm_token = word_tokenize(text, engine=\"newmm\")\n",
    "newmm_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_check_tokenizer(text,newmm_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " 'dataLot1': ['151', '185', '261', '307', '317', '321', '324', '461', '514', '518', '519', '520', '522', '524', '525', '526', '527', '528', '532', '533', '535', '554', '556', '558', '559', '561', '563', '564', '573', '574', '575', '577', '581', '624', '625', '643', '656', '672', '683', '687', '690', '695', '701', '711', '714', '723', '726', '791'], \n",
    " 'datalot2': ['12', '17', '39', '51', '55', '74', '76', '77', '78', '81', '92', '124', '126', '134', '138', '151', '152', '153', '157', '191', '198', '215', '219', '237', '282', '308', '318', '350', '388', '391', '393', '394', '400', '403', '407', '410', '411', '415', '416', '420', '425', '428', '464', '475', '506', '593'], \n",
    " 'datalot3': ['23', '25', '49', '65', '67', '110', '116', '118', '120', '125', '138', '166', '183', '184', '207', '248', '249', '250', '255', '263', '274', '275', '278', '279', '280', '284', '286', '323', '325', '336', '339', '348', '388', '389', '391', '417', '418', '419', '421', '423', '424', '425', '427', '428', '429', '432', '433', '434', '435', '437', '440', '443', '449', '455', '467', '477', '495', '499', '500', '509', '511', '514', '519', '524', '542', '544']\n",
    "}\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapping = {'datalot1': ['151', '185', '261', '307', '317', '321', '324', '461', '514', '518', '519', '520', '522', '524', '525', '526', '527', '528', '532', '533', '535', '554', '556', '558', '559', '561', '563', '564', '573', '574', '575', '577', '581', '624', '625', '643', '656', '672', '683', '687', '690', '695', '701', '711', '714', '723', '726', '791'], 'datalot2': ['12', '17', '39', '51', '55', '74', '76', '77', '78', '81', '92', '124', '126', '134', '138', '151', '152', '153', '157', '191', '198', '215', '219', '237', '282', '308', '318', '350', '388', '391', '393', '394', '400', '403', '407', '410', '411', '415', '416', '420', '425', '428', '464', '475', '506', '593'], 'datalot3': ['23', '25', '49', '65', '67', '110', '116', '118', '120', '125', '138', '166', '183', '184', '207', '248', '249', '250', '255', '263', '274', '275', '278', '279', '280', '284', '286', '323', '325', '336', '339', '348', '388', '389', '391', '417', '418', '419', '421', '423', '424', '425', '427', '428', '429', '432', '433', '434', '435', '437', '440', '443', '444', '445', '446', '448', '449', '455', '467', '477', '495', '499', '500', '509', '511', '514', '519', '524', '542', '544', '556', '560', '568', '572'], 'datalot4': ['10', '65', '74', '80', '84', '92', '98', '99', '100', '101', '110', '155', '169', '171', '188', '243', '249', '251', '258', '264', '265', '288', '435', '437', '438', '467', '491', '505', '516', '569', '577', '578', '601', '619', '620', '621', '624', '640', '651', '658', '666', '667', '668', '726', '734', '735', '740', '752', '812', '813', '817', '818', '819', '821', '822', '833', '841', '843', '844', '849', '857', '865', '885', '888', '895', '928', '931', '932', '934', '936', '939', '942', '943', '945', '946', '947', '948', '950', '951', '952', '957', '958', '959', '960', '961', '963', '964', '967', '968', '969', '970', '971', '972', '973', '974', '975', '977', '978', '980', '982', '984', '985', '987', '988', '990', '992', '994', '995', '996', '997', '998', '999', '1000', '1001', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1029', '1032', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1057', '1058', '1059', '1152', '1161', '1189', '1193', '1199']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "46\n",
      "74\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "for x in overlapping.items():\n",
    "    print(len(x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(48+46+74+167) # 335"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'datalot1': ['151', '185', '261', '307', '317', '321', '324', '461', '514', '518', '519', '520', '522', '524', '525', '526', '527', '528', '532', '533', '535', '554', '556', '558', '559', '561', '563', '564', '573', '574', '575', '577', '581', '624', '625', '643', '656', '672', '683', '687', '690', '695', '701', '711', '714', '723', '726', '791'],\n",
    " 'datalot2': ['12', '17', '39', '51', '55', '74', '76', '77', '78', '81', '92', '124', '126', '134', '138', '151', '152', '153', '157', '191', '198', '215', '219', '237', '282', '308', '318', '350', '388', '391', '393', '394', '400', '403', '407', '410', '411', '415', '416', '420', '425', '428', '464', '475', '506', '593'], \n",
    " 'datalot3': ['23', '25', '49', '65', '67', '110', '116', '118', '120', '125', '138', '166', '183', '184', '207', '248', '249', '250', '255', '263', '274', '275', '278', '279', '280', '284', '286', '323', '325', '336', '339', '348', '388', '389', '391', '417', '418', '419', '421', '423', '424', '425', '427', '428', '429', '432', '433', '434', '435', '437', '440', '443', '444', '445', '446', '448', '449', '455', '467', '477', '495', '499', '500', '509', '511', '514', '519', '524', '542', '544', '556', '560', '568', '572'],\n",
    " 'datalot4': ['10', '65', '74', '80', '84', '92', '98', '99', '100', '101', '110', '155', '169', '171', '188', '243', '249', '251', '258', '264', '265', '288', '435', '437', '438', '467', '491', '505', '516', '569', '577', '578', '601', '619', '620', '621', '624', '640', '651', '658', '666', '667', '668', '726', '734', '735', '740', '752', '812', '813', '817', '818', '819', '821', '822', '833', '841', '843', '844', '849', '857', '865', '885', '888', '895', '928', '931', '932', '934', '936', '939', '942', '943', '945', '946', '947', '948', '950', '951', '952', '957', '958', '959', '960', '961', '963', '964', '967', '968', '969', '970', '971', '972', '973', '974', '975', '977', '978', '980', '982', '984', '985', '987', '988', '990', '992', '994', '995', '996', '997', '998', '999', '1000', '1001', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017', '1019', '1020', '1021', '1022', '1023', '1024', '1025', '1026', '1027', '1029', '1032', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052', '1053', '1054', '1055', '1056', '1057', '1058', '1059', '1152', '1161', '1189', '1193', '1199']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:model] *",
   "language": "python",
   "name": "conda-env-model-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
